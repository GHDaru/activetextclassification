{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec39d8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# =============================================================================\n",
    "# Célula 1: Imports e Configurações Globais\n",
    "# =============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import traceback\n",
    "import glob # Para encontrar arquivos de log\n",
    "\n",
    "# --- Imports da Biblioteca ---\n",
    "try:\n",
    "    from activetextclassification.data_preparation import load_and_prepare_data\n",
    "    from activetextclassification.models import get_model # BaseTextClassifier, BaseFeatureClassifier não são mais usados diretamente aqui\n",
    "    from activetextclassification.embeddings import get_embedder # BaseEmbedder\n",
    "    from activetextclassification.optimization.genetic_l0_optimizer import GeneticL0Optimizer\n",
    "    from activetextclassification.utils import preprocess_label\n",
    "    # --- NOVO IMPORT DE VISUALIZAÇÃO ---\n",
    "    from activetextclassification.visualization.ag_plots import (\n",
    "        plot_ag_convergence,\n",
    "        plot_ag_population_evolution_boxplots,\n",
    "        plot_ag_time_stats\n",
    "    )\n",
    "    print(\"Módulos da biblioteca activetextclassification importados.\")\n",
    "except Exception as e: \n",
    "    print(f\"ERRO ao importar biblioteca: {e}\") \n",
    "    raise e\n",
    "\n",
    "# --- Autoreload ---\n",
    "try: \n",
    "    %load_ext autoreload; \n",
    "    %autoreload 2; \n",
    "    print(\"Autoreload ativado.\")\n",
    "except Exception: pass\n",
    "\n",
    "# --- Parâmetros do Experimento de Otimização ---\n",
    "# <<< MUDE AQUI CONFORME NECESSÁRIO >>>\n",
    "DATA_FILE = r'../data/dataset.csv'\n",
    "TEXT_COLUMN = 'nm_item'\n",
    "LABEL_COLUMN = 'nm_product'\n",
    "MIN_SAMPLES_PREPROC = 5\n",
    "RARE_LABEL_PREPROC = \"_RARE_\"\n",
    "CLASSIFIER_CONFIG_AG = {\n",
    "    'type': 'PVBin',\n",
    "    'params': {'method':'binary', 'query':'binary', 'norm':None, 'query_norm':None, 'ngram_range': [1,2]}\n",
    "}\n",
    "GLOBAL_EMBEDDER_CONFIG_AG = None\n",
    "L0_SIZE_TO_OPTIMIZE = 20000 # Teste com tamanho pequeno\n",
    "POPULATION_SIZE_AG = 20   # População pequena para teste\n",
    "N_GENERATIONS_AG = 100    # Poucas gerações para teste\n",
    "CROSSOVER_RATE_AG = 0.8\n",
    "MUTATION_RATE_AG = 0.2\n",
    "MUTATION_STRENGTH_AG = 100 # Mutar 1 gene\n",
    "ELITISM_RATE_AG = 0.05\n",
    "TOURNAMENT_SIZE_AG = 3\n",
    "LOG_DETAILED_FITNESS_AG = True # Ativar log detalhado\n",
    "\n",
    "# Nomes base para arquivos de saída (serão sufixados)\n",
    "OPTIMIZATION_DIR = f\"ag_optimization_results_L0_{L0_SIZE_TO_OPTIMIZE}\" # Diretório para organizar\n",
    "os.makedirs(OPTIMIZATION_DIR, exist_ok=True) # Criar diretório\n",
    "\n",
    "OPTIMIZATION_HISTORY_BASE_FILE = os.path.join(OPTIMIZATION_DIR, f\"ag_history\")\n",
    "BEST_L0_BASE_FILE = os.path.join(OPTIMIZATION_DIR, f\"ag_best_l0\")\n",
    "DETAILED_FITNESS_LOG_BASE_FILE = os.path.join(OPTIMIZATION_DIR, f\"ag_detailed_fitness\")\n",
    "# <<< FIM MUDE AQUI >>>\n",
    "\n",
    "print(f\"Experimento de Otimização de L0 com AG\") # ... (outros prints de config)\n",
    "print(f\"Resultados serão salvos em: {os.path.abspath(OPTIMIZATION_DIR)}\")\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0429871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Célula 2: Carregar Dados e Preparar Embedder Global (se necessário)\n",
    "# =============================================================================\n",
    "# ... (Código da Célula 2 como na sua última versão, carregando df_full_ag,\n",
    "#      all_possible_labels_ag, e preparando embedder_instance_ag se necessário) ...\n",
    "print(\"\\n--- Carregando e Preparando Dataset Completo para AG ---\")\n",
    "df_full_ag = None; all_possible_labels_ag = []; embedder_instance_ag = None\n",
    "try:\n",
    "    _, _, _, _, all_possible_labels_ag = load_and_prepare_data(file_path=DATA_FILE, text_column=TEXT_COLUMN, label_column=LABEL_COLUMN,min_samples_per_class=MIN_SAMPLES_PREPROC, rare_group_label=RARE_LABEL_PREPROC,population_size=0.99)\n",
    "    if not all_possible_labels_ag: raise ValueError(\"Labels não carregados.\")\n",
    "    file_ext_ag = os.path.splitext(DATA_FILE)[1].lower()\n",
    "    if file_ext_ag == '.csv': df_full_ag = pd.read_csv(DATA_FILE)\n",
    "    elif file_ext_ag in ['.xlsx', '.xls']: df_full_ag = pd.read_excel(DATA_FILE)\n",
    "    df_full_ag.dropna(subset=[TEXT_COLUMN, LABEL_COLUMN], inplace=True)\n",
    "    df_full_ag[LABEL_COLUMN] = df_full_ag[LABEL_COLUMN].apply(preprocess_label).astype(str)\n",
    "    if MIN_SAMPLES_PREPROC > 1:\n",
    "        counts = df_full_ag[LABEL_COLUMN].value_counts(); rare = counts[counts < MIN_SAMPLES_PREPROC].index.tolist()\n",
    "        if rare: df_full_ag[LABEL_COLUMN] = df_full_ag[LABEL_COLUMN].replace(rare, RARE_LABEL_PREPROC)\n",
    "    df_full_ag = df_full_ag[df_full_ag[LABEL_COLUMN].isin(all_possible_labels_ag)].copy().reset_index(drop=True)\n",
    "    if df_full_ag.empty or L0_SIZE_TO_OPTIMIZE > len(df_full_ag): raise ValueError(\"Dataset AG inválido ou L0 muito grande.\")\n",
    "    clf_type_ag = CLASSIFIER_CONFIG_AG.get('type')\n",
    "    if clf_type_ag in ['GNB', 'LSVC', 'LR', 'SGD'] and GLOBAL_EMBEDDER_CONFIG_AG:\n",
    "        embedder_instance_ag = get_embedder(GLOBAL_EMBEDDER_CONFIG_AG)\n",
    "        embedder_instance_ag.fit(df_full_ag[TEXT_COLUMN].tolist(), df_full_ag[LABEL_COLUMN].tolist())\n",
    "    elif clf_type_ag in ['GNB', 'LSVC', 'LR', 'SGD'] and not GLOBAL_EMBEDDER_CONFIG_AG: raise ValueError(\"Embedder config ausente.\")\n",
    "    print(f\"Dataset AG preparado: {len(df_full_ag)} amostras.\")\n",
    "except Exception as e: print(f\"ERRO dados AG: {e}\"); raise SystemExit(\"Falha dados AG.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1966bf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# =============================================================================\n",
    "# Célula 3: Função para Executar e Salvar Otimização (com checagem de existência)\n",
    "# =============================================================================\n",
    "\n",
    "def run_and_save_optimization_with_resume(\n",
    "    df_full, optimization_goal, fitness_metric_to_optimize, seed_offset=0, force_rerun=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Executa o AG, salva resultados, e pula se o arquivo de histórico já existir (a menos que force_rerun).\n",
    "    \"\"\"\n",
    "    goal_suffix = f\"_{fitness_metric_to_optimize.split('_')[0].upper()}_{optimization_goal.upper()}\"\n",
    "    file_hist_check = f\"{OPTIMIZATION_HISTORY_BASE_FILE}{goal_suffix}.xlsx\"\n",
    "    file_best_l0_check = f\"{BEST_L0_BASE_FILE}{goal_suffix}.csv\"\n",
    "    detailed_log_check = f\"{DETAILED_FITNESS_LOG_BASE_FILE}{fitness_metric_to_optimize.split('_')[0].upper()}_{optimization_goal.upper()}.csv\"\n",
    "\n",
    "    # --- LÓGICA DE \"NÃO REFAZER\" ---\n",
    "    if os.path.exists(file_hist_check) and os.path.exists(file_best_l0_check) and not force_rerun:\n",
    "        print(f\"\\n{'='*10} Otimização para {goal_suffix} JÁ EXISTE. Pulando. {'='*10}\")\n",
    "        print(f\" - Histórico: {file_hist_check}\")\n",
    "        print(f\" - Melhor L0: {file_best_l0_check}\")\n",
    "        # Tentar carregar resultados existentes para retorno\n",
    "        try:\n",
    "            history_df = pd.read_excel(file_hist_check)\n",
    "            # Para best_l0_indices e best_actual_perf, precisaríamos de uma forma de recuperá-los\n",
    "            # do arquivo best_l0 ou de um log de sumário. Por simplicidade, retornamos None se pulado.\n",
    "            # Ou, se o CSV do melhor L0 tem a performance, podemos lê-la.\n",
    "            best_l0_df_saved = pd.read_csv(file_best_l0_check)\n",
    "            best_perf_saved = best_l0_df_saved['metric_value'].iloc[0] if not best_l0_df_saved.empty else np.nan\n",
    "            # Índices não são diretamente salvos, apenas o conteúdo.\n",
    "            # Poderíamos salvar os índices no CSV do melhor L0 se quisermos reconstruir.\n",
    "            # Por ora, retornaremos None para índices se pulado.\n",
    "            return None, best_perf_saved, history_df\n",
    "        except Exception as e_load:\n",
    "            print(f\"AVISO: Falha ao carregar resultados existentes para {goal_suffix}: {e_load}\")\n",
    "            return None, np.nan, pd.DataFrame()\n",
    "    # --- FIM \"NÃO REFAZER\" ---\n",
    "\n",
    "\n",
    "    print(f\"\\n{'='*15} Iniciando Otimização (L0Tam: {L0_SIZE_TO_OPTIMIZE}, Obj: {optimization_goal.upper()}, Métrica: {fitness_metric_to_optimize}) {'='*15}\")\n",
    "\n",
    "    ag_optimizer = GeneticL0Optimizer(\n",
    "        df_full=df_full, text_column=TEXT_COLUMN, label_column=LABEL_COLUMN,\n",
    "        classifier_config=CLASSIFIER_CONFIG_AG, initial_l0_size=L0_SIZE_TO_OPTIMIZE,\n",
    "        all_possible_labels=all_possible_labels_ag, population_size=POPULATION_SIZE_AG,\n",
    "        n_generations=N_GENERATIONS_AG, crossover_rate=CROSSOVER_RATE_AG,\n",
    "        mutation_rate=MUTATION_RATE_AG, mutation_strength=MUTATION_STRENGTH_AG,\n",
    "        elitism_rate=ELITISM_RATE_AG, fitness_metric=fitness_metric_to_optimize,\n",
    "        optimization_goal=optimization_goal, tournament_size=TOURNAMENT_SIZE_AG,\n",
    "        random_seed=42 + seed_offset, embedder=embedder_instance_ag,\n",
    "        log_detailed_fitness=LOG_DETAILED_FITNESS_AG, # Usar config global\n",
    "        detailed_log_file=detailed_log_check # Passar o nome do arquivo correto\n",
    "    )\n",
    "\n",
    "    best_l0_indices, best_actual_perf, history_df = ag_optimizer.run_optimization()\n",
    "\n",
    "    # Salvar Histórico\n",
    "    if history_df is not None and not history_df.empty:\n",
    "        print(f\"Salvando histórico ({goal_suffix}) em: {file_hist_check}\")\n",
    "        try: history_df.to_excel(file_hist_check, index=False)\n",
    "        except Exception as e: print(f\"Erro salvar histórico AG ({goal_suffix}): {e}\")\n",
    "    else: print(f\"Nenhum histórico de otimização para salvar ({goal_suffix}).\")\n",
    "\n",
    "    # Salvar Melhor/Pior L0\n",
    "    if best_l0_indices is not None and len(best_l0_indices) > 0:\n",
    "        print(f\"Salvando L0 (Obj: {optimization_goal}, Perf: {best_actual_perf:.4f}) em: {file_best_l0_check}\")\n",
    "        best_l0_df = df_full.iloc[best_l0_indices][[TEXT_COLUMN, LABEL_COLUMN]].copy()\n",
    "        best_l0_df['metric_value'] = best_actual_perf\n",
    "        best_l0_df['metric_type'] = fitness_metric_to_optimize\n",
    "        best_l0_df['optimization_goal'] = optimization_goal\n",
    "        best_l0_df['l0_indices_str'] = \",\".join(map(str, best_l0_indices)) # Salvar os índices também\n",
    "        try: best_l0_df.to_csv(file_best_l0_check, index=False, encoding='utf-8-sig')\n",
    "        except Exception as e: print(f\"Erro salvar L0 ({goal_suffix}): {e}\")\n",
    "    else: print(f\"Nenhum L0 encontrado (Obj: {optimization_goal}, {goal_suffix}).\")\n",
    "\n",
    "    return best_l0_indices, best_actual_perf, history_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9251073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# =============================================================================\n",
    "# Célula 4: Executar Otimizações\n",
    "# =============================================================================\n",
    "FORCE_RERUN_OPTIMIZATIONS = False # Mude para True para re-rodar tudo\n",
    "optimization_results = {}\n",
    "\n",
    "if df_full_ag is not None and not df_full_ag.empty:\n",
    "    # --- Otimizar para ACURÁCIA ---\n",
    "    res_acc_max = run_and_save_optimization_with_resume(df_full_ag, 'maximize', 'accuracy_on_full', 0, FORCE_RERUN_OPTIMIZATIONS)\n",
    "    optimization_results['ACC_MAX'] = {'indices': res_acc_max[0], 'performance': res_acc_max[1], 'history_df': res_acc_max[2]}\n",
    "\n",
    "    res_acc_min = run_and_save_optimization_with_resume(df_full_ag, 'minimize', 'accuracy_on_full', 100, FORCE_RERUN_OPTIMIZATIONS)\n",
    "    optimization_results['ACC_MIN'] = {'indices': res_acc_min[0], 'performance': res_acc_min[1], 'history_df': res_acc_min[2]}\n",
    "\n",
    "    # --- Otimizar para F1-SCORE ---\n",
    "    res_f1_max = run_and_save_optimization_with_resume(df_full_ag, 'maximize', 'f1_macro_on_full', 200, FORCE_RERUN_OPTIMIZATIONS)\n",
    "    optimization_results['F1_MAX'] = {'indices': res_f1_max[0], 'performance': res_f1_max[1], 'history_df': res_f1_max[2]}\n",
    "\n",
    "    res_f1_min = run_and_save_optimization_with_resume(df_full_ag, 'minimize', 'f1_macro_on_full', 300, FORCE_RERUN_OPTIMIZATIONS)\n",
    "    optimization_results['F1_MIN'] = {'indices': res_f1_min[0], 'performance': res_f1_min[1], 'history_df': res_f1_min[2]}\n",
    "\n",
    "    print(\"\\n--- Todas as Otimizações Programadas Concluídas/Puladas ---\")\n",
    "else:\n",
    "    print(\"ERRO: df_full_ag não está definido ou está vazio. Não é possível executar otimizações.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc162b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# =============================================================================\n",
    "# Célula 5: Visualização dos Resultados da Otimização AG\n",
    "# =============================================================================\n",
    "print(\"\\n--- Carregando e Plotando Resultados da Otimização AG ---\")\n",
    "\n",
    "# Loop para carregar e plotar cada resultado salvo (se não já em optimization_results)\n",
    "plot_configs = [\n",
    "    {'goal': 'maximize', 'metric': 'accuracy_on_full', 'key': 'ACC_MAX', 'title_metric': 'Acurácia'},\n",
    "    {'goal': 'minimize', 'metric': 'accuracy_on_full', 'key': 'ACC_MIN', 'title_metric': 'Acurácia'},\n",
    "    {'goal': 'maximize', 'metric': 'f1_macro_on_full', 'key': 'F1_MAX', 'title_metric': 'F1-Macro'},\n",
    "    {'goal': 'minimize', 'metric': 'f1_macro_on_full', 'key': 'F1_MIN', 'title_metric': 'F1-Macro'}\n",
    "]\n",
    "\n",
    "for p_config in plot_configs:\n",
    "    goal_suffix = f\"_{p_config['metric'].split('_')[0].upper()}_{p_config['goal'].upper()}\"\n",
    "    history_file = f\"{OPTIMIZATION_HISTORY_BASE_FILE}{goal_suffix}.xlsx\"\n",
    "    detailed_log_file = f\"{DETAILED_FITNESS_LOG_BASE_FILE}{p_config['metric'].split('_')[0].upper()}_{p_config['goal'].upper()}.csv\"\n",
    "    title_prefix = f\"AG {p_config['goal'].capitalize()} {p_config['title_metric']}\"\n",
    "\n",
    "    print(f\"\\n--- Visualizando para: {title_prefix} ---\")\n",
    "\n",
    "    # Carregar histórico se não estiver já no dict optimization_results ou se estiver vazio\n",
    "    history_df_plot = optimization_results.get(p_config['key'], {}).get('history_df')\n",
    "    if history_df_plot is None or history_df_plot.empty:\n",
    "        if os.path.exists(history_file):\n",
    "            try: history_df_plot = pd.read_excel(history_file)\n",
    "            except Exception as e: print(f\"  Erro ao carregar {history_file}: {e}\")\n",
    "        else: print(f\"  Arquivo de histórico {history_file} não encontrado.\")\n",
    "\n",
    "    # Plotar convergência\n",
    "    if history_df_plot is not None and not history_df_plot.empty:\n",
    "        plot_ag_convergence(history_df_plot, title_prefix=f\"Convergência - {title_prefix}\", l0_size=L0_SIZE_TO_OPTIMIZE)\n",
    "        plot_ag_time_stats(history_df_plot, title_prefix=f\"Tempo/Geração - {title_prefix}\", l0_size=L0_SIZE_TO_OPTIMIZE)\n",
    "\n",
    "    # Carregar e plotar boxplots da população\n",
    "    if LOG_DETAILED_FITNESS_AG and os.path.exists(detailed_log_file):\n",
    "        try:\n",
    "            df_detailed_plot = pd.read_csv(detailed_log_file)\n",
    "            # A métrica a ser plotada no boxplot é a que foi otimizada\n",
    "            metric_col_for_boxplot = p_config['metric'] # 'accuracy_on_full' ou 'f1_macro_on_full'\n",
    "            plot_ag_population_evolution_boxplots(\n",
    "                df_detailed_plot,\n",
    "                metric_to_plot=metric_col_for_boxplot,\n",
    "                title_prefix=f\"Evolução População - {title_prefix}\",\n",
    "                l0_size=L0_SIZE_TO_OPTIMIZE,\n",
    "                generation_step=max(1, N_GENERATIONS_AG // 5) # Plotar ~5 boxplots\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"  Erro ao carregar ou plotar log detalhado {detailed_log_file}: {e}\")\n",
    "    elif LOG_DETAILED_FITNESS_AG:\n",
    "        print(f\"  Arquivo de log detalhado {detailed_log_file} não encontrado.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
